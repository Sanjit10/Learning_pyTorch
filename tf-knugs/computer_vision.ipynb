{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Import torchvision\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchmetrics\n",
    "\n",
    "#Import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# write device agnostic code\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "def tensor_to_image(tensor):\n",
    "    tensor = tensor*255\n",
    "    tensor = np.array(tensor, dtype=np.uint8)\n",
    "    if np.ndim(tensor)>3:\n",
    "        assert tensor.shape[0] == 1\n",
    "        tensor = tensor[0]\n",
    "    return Image.fromarray(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get a dataset fashion MNIST\n",
    "\n",
    "# Setup Training data\n",
    "\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root = 'tf-knugs/datasets',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = transforms.ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root = 'tf-knugs/datasets',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = transforms.ToTensor()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup data loaders\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset= train_data,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset= test_data,\n",
    "    batch_size= BATCH_SIZE,\n",
    "    shuffle= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders:(<torch.utils.data.dataloader.DataLoader object at 0x7f204014dfd0>, <torch.utils.data.dataloader.DataLoader object at 0x7f2042bdff90>) \n",
      "Length of train_dataloader: 1875 batches of 32...\n",
      "Length of test_dataloader: 313 batches of 32...\n"
     ]
    }
   ],
   "source": [
    "print(f\"DataLoaders:{train_dataloader, test_dataloader} \")\n",
    "print(f\"Length of train_dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}...\")\n",
    "print(f\"Length of test_dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(train_dataloader)*BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 28, 28]), torch.Size([32]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check out whats inside the training data loader\n",
    "\n",
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "train_features_batch.shape, train_labels_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show sample\n",
    "# torch.manual_seed(42)\n",
    "class_names = train_data.classes\n",
    "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
    "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.title(class_names[label])\n",
    "plt.axis(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class FashionMNISTModelV0(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(), # neural networks like their inputs in vector form\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units), # in_features = number of features in a data sample (784 pixels)\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FashionMNISTModelV0(\n",
       "  (layer_stack): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
       "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Need to setup model with input parameters\n",
    "model_0 = FashionMNISTModelV0(input_shape=784, # one for every pixel (28x28)\n",
    "    hidden_units=10, # how many units in the hiden layer\n",
    "    output_shape=len(class_names) # one for every class\n",
    ")\n",
    "model_0.to(device) # keep model on CPU to begin with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import accuracy metric\n",
    "from helper_functions import accuracy_fn # Note: could also use torchmetrics.Accuracy(task = 'multiclass', num_classes=len(class_names)).to(device)\n",
    "\n",
    "# Setup loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss() # this is also called \"criterion\"/\"cost function\" in some places\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a function to time our expiriment\n",
    "\n",
    "Machine learning is very expirimental.\n",
    "\n",
    "Two main things we want ot keep track of is:\n",
    "1. Model's performance (loss, acc)etc\n",
    "2. Models spped or how fast it runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "    \"\"\"Prints difference between start and end time.\n",
    "\n",
    "    Args:\n",
    "        start (float): Start time of computation (preferred in timeit format).\n",
    "        end (float): End time of computation.\n",
    "        device ([type], optional): Device that compute is running on. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        float: time between start and end in seconds (higher is longer).\n",
    "    \"\"\"\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_shape_device(*args):\n",
    "    \"\"\"\n",
    "    This function prints the shape, data type and device of the given tensors or numpy arrays.\n",
    "\n",
    "    Parameters:\n",
    "    *args (torch tensor or numpy array): Variable length argument list of tensors or arrays.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    for arg in args:\n",
    "        if torch.is_tensor(arg):\n",
    "            print(f\"Shape: {arg.shape} | Device: {arg.device}| Type : {arg.dtype} | torch tensor\")\n",
    "        elif isinstance(arg, np.ndarray):\n",
    "            print(f\"Shape: {arg.shape} | Device: CPU | Type : {arg.dtype} | numpy array\")\n",
    "        else:\n",
    "            print(\"Input type not supported. Please provide a torch tensor or a numpy array.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a training loop and trainin a model pn batches of data\n",
    "\n",
    "1. Loop throung epoch.\n",
    "2. Loop through training batches, perform training steps , calculate the train loss *per batch*.\n",
    "3. Loop through testing batches, perform tetsing steps, claculate the test loos *per batch*.\n",
    "4. Print out whats happening.\n",
    "5. Time is all (for analytics and fun)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.to(device)\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        # Send data to GPU\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Calculate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy_fn(y_true=y,\n",
    "                                 y_pred=y_pred.argmax(dim=1)) # Go from logits -> pred labels\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate loss and accuracy per epoch and print out what's happening\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "def test_step(data_loader: torch.utils.data.DataLoader,\n",
    "              model: torch.nn.Module,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "              device: torch.device = device):\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.to(device)\n",
    "    model.eval() # put model in eval mode\n",
    "    # Turn on inference context manager\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            # Send data to GPU\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # 1. Forward pass\n",
    "            test_pred = model(X)\n",
    "\n",
    "            # 2. Calculate loss and accuracy\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            test_acc += accuracy_fn(y_true=y,\n",
    "                y_pred=test_pred.argmax(dim=1) # Go from logits -> pred labels\n",
    "            )\n",
    "\n",
    "        # Adjust metrics and print out\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "271990664eca403eb1cd7dcf26c21d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "-------\n",
      "Train loss: 0.59039 | Train accuracy: 79.17%\n",
      "Test loss: 0.51016 | Test accuracy: 82.04%\n",
      "\n",
      "Epoch: 1\n",
      "-------\n",
      "Train loss: 0.47435 | Train accuracy: 83.30%\n",
      "Test loss: 0.52677 | Test accuracy: 81.68%\n",
      "\n",
      "Epoch: 2\n",
      "-------\n",
      "Train loss: 0.45367 | Train accuracy: 84.19%\n",
      "Test loss: 0.51264 | Test accuracy: 83.00%\n",
      "\n",
      "Train time on cuda:0: 52.481 seconds\n"
     ]
    }
   ],
   "source": [
    "# Import tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "from helper_functions import accuracy_fn\n",
    "\n",
    "# Set the seed and start the timer\n",
    "torch.manual_seed(42)\n",
    "train_time_start_on_gpu = timer()\n",
    "\n",
    "\n",
    "# Set the number of epochs (we'll keep this small for faster training times)\n",
    "epochs = 3\n",
    "\n",
    "# Create training and testing loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n-------\")\n",
    "\n",
    "    #Train\n",
    "    train_step(\n",
    "        model= model_0,\n",
    "        data_loader= train_dataloader,\n",
    "        loss_fn= loss_fn,\n",
    "        optimizer= optimizer,\n",
    "        accuracy_fn= accuracy_fn,\n",
    "        device= device\n",
    "    )\n",
    "\n",
    "    #test\n",
    "    test_step(\n",
    "        model= model_0,\n",
    "        data_loader= test_dataloader,\n",
    "        loss_fn= loss_fn,\n",
    "        accuracy_fn= accuracy_fn,\n",
    "        device = device\n",
    "    )\n",
    "\n",
    "\n",
    "# Calculate training time\n",
    "train_time_end_on_gpu = timer()\n",
    "total_train_time_model_0 = print_train_time(start=train_time_start_on_gpu,\n",
    "                                           end=train_time_end_on_gpu,\n",
    "                                           device=str(next(model_0.parameters()).device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predicitions and get model results\n",
    "\n",
    "def eval_model(model: torch.nn.Module,\n",
    "               dataloader: DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               accuracy_fn\n",
    "):\n",
    "    \"\"\"Returns a dictonary condataining prediciton parameter of a module\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): model to evaluate\n",
    "        dataloader (DataLoader): a dataloader that loads data by batches\n",
    "        loss_fn (torch.nn.Module): function that calculates loss\n",
    "        accuracy_fn (_type_): function that claculates accuracy\n",
    "    \"\"\"\n",
    "    loss, acc = 0,0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X,y in tqdm(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # Make predicitons\n",
    "            y_pred = model(X)\n",
    "\n",
    "            # Accumulate the loss and accuracy values\n",
    "            acc += accuracy_fn(y_true= y, y_pred= y_pred.argmax(dim=1))\n",
    "            loss = loss_fn(y_pred, y)\n",
    "\n",
    "        #Scale loss and acc to find the average loss/acc per batch\n",
    "        loss /= len(dataloader)\n",
    "        acc /= len(dataloader)\n",
    "\n",
    "    return {\n",
    "        \"model_name\" : model.__class__.__name__,\n",
    "        \"model_loss\": loss.item(),\n",
    "        \"model_acc\": acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e2125716d24347914a67ba466db755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'FashionMNISTModelV0', 'model_loss': 0.0010662450222298503, 'model_acc': 83.00718849840256}\n"
     ]
    }
   ],
   "source": [
    "# Use the function to calculate\n",
    "model0_results = eval_model(\n",
    "    model=model_0,\n",
    "    dataloader= test_dataloader,\n",
    "    accuracy_fn= accuracy_fn,\n",
    "    loss_fn= loss_fn\n",
    ")\n",
    "print(model0_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creatiung a convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTModelv2(nn.Module):\n",
    "    \"\"\"\n",
    "    Model architechture that replicates the TinyVGG\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 input_shape: int,\n",
    "                 hidden_units: int,\n",
    "                 output_shape: int):\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels= input_shape,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size= 3,\n",
    "                stride = 1,\n",
    "                padding=1), #Setting hyperparameters for 2d data\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels= hidden_units,\n",
    "                out_channels= hidden_units,\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "                stride=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "                stride=1\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "                stride=1\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d( kernel_size=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(\n",
    "                in_features= hidden_units*7*7,\n",
    "                out_features= output_shape\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model_2 = FashionMNISTModelv2(\n",
    "    input_shape= 1,\n",
    "    hidden_units= 10,\n",
    "    output_shape= len(class_names)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup a loss and optimizer funciton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(\n",
    "    params=model_2.parameters(),\n",
    "    lr=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eaf7557b08e44dcad4fceebbd5573e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "-------\n",
      "Train loss: 0.30508 | Train accuracy: 89.05%\n",
      "Test loss: 0.32201 | Test accuracy: 88.24%\n",
      "\n",
      "Epoch: 1\n",
      "-------\n",
      "Train loss: 0.29167 | Train accuracy: 89.30%\n",
      "Test loss: 0.33901 | Test accuracy: 87.74%\n",
      "\n",
      "Epoch: 2\n",
      "-------\n",
      "Train loss: 0.28126 | Train accuracy: 89.82%\n",
      "Test loss: 0.32067 | Test accuracy: 88.76%\n",
      "\n",
      "Train time on cuda:0: 66.765 seconds\n"
     ]
    }
   ],
   "source": [
    "# Import tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "from helper_functions import accuracy_fn\n",
    "\n",
    "# Set the seed and start the timer\n",
    "torch.manual_seed(42)\n",
    "train_time_start_on_gpu = timer()\n",
    "\n",
    "\n",
    "# Set the number of epochs (we'll keep this small for faster training times)\n",
    "epochs = 3\n",
    "\n",
    "# Create training and testing loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n-------\")\n",
    "\n",
    "    #Train\n",
    "    train_step(\n",
    "        model= model_2,\n",
    "        data_loader= train_dataloader,\n",
    "        loss_fn= loss_fn,\n",
    "        optimizer= optimizer,\n",
    "        accuracy_fn= accuracy_fn,\n",
    "        device= device\n",
    "    )\n",
    "\n",
    "    #test\n",
    "    test_step(\n",
    "        model= model_2,\n",
    "        data_loader= test_dataloader,\n",
    "        loss_fn= loss_fn,\n",
    "        accuracy_fn= accuracy_fn,\n",
    "        device = device\n",
    "    )\n",
    "\n",
    "\n",
    "# Calculate training time\n",
    "train_time_end_on_gpu = timer()\n",
    "total_train_time_model_0 = print_train_time(start=train_time_start_on_gpu,\n",
    "                                           end=train_time_end_on_gpu,\n",
    "                                           device=str(next(model_2.parameters()).device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
