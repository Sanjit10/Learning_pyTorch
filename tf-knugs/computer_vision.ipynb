{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Import torchvision\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchmetrics\n",
    "\n",
    "#Import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write device agnostic code\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = \"cpu\"\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "def tensor_to_image(tensor):\n",
    "    tensor = tensor*255\n",
    "    tensor = np.array(tensor, dtype=np.uint8)\n",
    "    if np.ndim(tensor)>3:\n",
    "        assert tensor.shape[0] == 1\n",
    "        tensor = tensor[0]\n",
    "    return Image.fromarray(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get a dataset fashion MNIST\n",
    "\n",
    "# Setup Training data\n",
    "\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root = 'tf-knugs/datasets',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = transforms.ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root = 'tf-knugs/datasets',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = transforms.ToTensor()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup data loaders\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset= train_data,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset= test_data,\n",
    "    batch_size= BATCH_SIZE,\n",
    "    shuffle= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"DataLoaders:{train_dataloader, test_dataloader} \")\n",
    "print(f\"Length of train_dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}...\")\n",
    "print(f\"Length of test_dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data))\n",
    "print(len(train_dataloader)*BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check out whats inside the training data loader\n",
    "\n",
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "train_features_batch.shape, train_labels_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show sample\n",
    "# torch.manual_seed(42)\n",
    "class_names = train_data.classes\n",
    "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
    "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.title(class_names[label])\n",
    "plt.axis(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class FashionMNISTModelV0(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(), # neural networks like their inputs in vector form\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units), # in_features = number of features in a data sample (784 pixels)\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Need to setup model with input parameters\n",
    "model_0 = FashionMNISTModelV0(input_shape=784, # one for every pixel (28x28)\n",
    "    hidden_units=10, # how many units in the hiden layer\n",
    "    output_shape=len(class_names) # one for every class\n",
    ")\n",
    "model_0.to(device) # keep model on CPU to begin with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import accuracy metric\n",
    "from helper_functions import accuracy_fn # Note: could also use torchmetrics.Accuracy(task = 'multiclass', num_classes=len(class_names)).to(device)\n",
    "\n",
    "# Setup loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss() # this is also called \"criterion\"/\"cost function\" in some places\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a function to time our expiriment\n",
    "\n",
    "Machine learning is very expirimental.\n",
    "\n",
    "Two main things we want ot keep track of is:\n",
    "1. Model's performance (loss, acc)etc\n",
    "2. Models spped or how fast it runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "    \"\"\"Prints difference between start and end time.\n",
    "\n",
    "    Args:\n",
    "        start (float): Start time of computation (preferred in timeit format).\n",
    "        end (float): End time of computation.\n",
    "        device ([type], optional): Device that compute is running on. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        float: time between start and end in seconds (higher is longer).\n",
    "    \"\"\"\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_shape_device(*args):\n",
    "    \"\"\"\n",
    "    This function prints the shape, data type and device of the given tensors or numpy arrays.\n",
    "\n",
    "    Parameters:\n",
    "    *args (torch tensor or numpy array): Variable length argument list of tensors or arrays.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    for arg in args:\n",
    "        if torch.is_tensor(arg):\n",
    "            print(f\"Shape: {arg.shape} | Device: {arg.device}| Type : {arg.dtype} | torch tensor\")\n",
    "        elif isinstance(arg, np.ndarray):\n",
    "            print(f\"Shape: {arg.shape} | Device: CPU | Type : {arg.dtype} | numpy array\")\n",
    "        else:\n",
    "            print(\"Input type not supported. Please provide a torch tensor or a numpy array.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a training loop and trainin a model pn batches of data\n",
    "\n",
    "1. Loop throung epoch.\n",
    "2. Loop through training batches, perform training steps , calculate the train loss *per batch*.\n",
    "3. Loop through testing batches, perform tetsing steps, claculate the test loos *per batch*.\n",
    "4. Print out whats happening.\n",
    "5. Time is all (for analytics and fun)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(\n",
    "    model: torch.nn.Module,\n",
    "    data_loader: torch.utils.data.DataLoader,\n",
    "    loss_fn : torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    accuracy_fn,\n",
    "    device:torch.device = device\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains your model : use within a training loop\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): _description_\n",
    "        data_loader (torch.utils.data.DataLoader): _description_\n",
    "        loss_fn (torch.nn.Module): _description_\n",
    "        optimizer (torch.optim.Optimizer): _description_\n",
    "        accuracy_fn (_type_): _description_\n",
    "        device (torch.device, optional): _description_. Defaults to device.\n",
    "    \"\"\"\n",
    "\n",
    "    ### Training\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    #Put model in Training mode\n",
    "    model.train()\n",
    "\n",
    "    # Add a loop to loop through training batches\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model_0(X)\n",
    "\n",
    "        # 2. Calculate loss (per batch)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss # accumulatively add up the loss per epoch\n",
    "        train_acc += accuracy_fn(y_true= y,\n",
    "                                 y_pred= y_pred.argmax(dim=1))\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print out how many samples have been seen\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(data_loader.dataset)} samples\")\n",
    "\n",
    "    # Divide total train loss and accuracy by length of train dataloader (average loss and accuracy per batch per epoch)\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"Train Loss : {train_loss: .5f} | Train acc : {train_acc: .2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(\n",
    "    model: torch.nn.Module,\n",
    "    data_loader: torch.utils.data.DataLoader,\n",
    "    loss_fn : torch.nn.Module,\n",
    "    accuracy_fn,\n",
    "    device:torch.device = device\n",
    "):\n",
    "    \"\"\"\n",
    "    Tests the model on test data set\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): _description_\n",
    "        data_loader (torch.utils.data.DataLoader): _description_\n",
    "        loss_fn (torch.nn.Module): _description_\n",
    "        accuracy_fn (_type_): _description_\n",
    "        device (torch.device, optional): _description_. Defaults to device.\n",
    "    \"\"\"\n",
    "    ### Testing\n",
    "    # Setup variables for accumulatively adding up loss and accuracy\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    #Put the model in eval mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # 1. Forward pass\n",
    "            test_pred = model(X)\n",
    "\n",
    "            # 2. Calculate loss (accumatively)\n",
    "            test_loss += loss_fn(test_pred, y) # accumulatively add up the loss per epoch\n",
    "\n",
    "            # 3. Calculate accuracy (preds need to be same as y_true)\n",
    "            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
    "\n",
    "        # Calculations on test metrics need to happen inside torch.inference_mode()\n",
    "        # Divide total test loss by length of test dataloader (per batch)\n",
    "        test_loss /= len(data_loader)\n",
    "\n",
    "        # Divide total accuracy by length of test dataloader (per batch)\n",
    "        test_acc /= len(data_loader)\n",
    "\n",
    "    ## Print out what's happening\n",
    "    print(f\"\\nTest loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "from helper_functions import accuracy_fn\n",
    "\n",
    "# Set the seed and start the timer\n",
    "torch.manual_seed(42)\n",
    "train_time_start_on_gpu = timer()\n",
    "\n",
    "\n",
    "# Set the number of epochs (we'll keep this small for faster training times)\n",
    "epochs = 3\n",
    "\n",
    "# Create training and testing loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n-------\")\n",
    "\n",
    "    #Train\n",
    "    train_step(\n",
    "        model= model_0,\n",
    "        data_loader= train_dataloader,\n",
    "        loss_fn= loss_fn,\n",
    "        optimizer= optimizer,\n",
    "        accuracy_fn= accuracy_fn,\n",
    "        device= device\n",
    "    )\n",
    "\n",
    "    #test\n",
    "    test_step(\n",
    "        model= model_0,\n",
    "        data_loader= test_dataloader,\n",
    "        loss_fn= loss_fn,\n",
    "        accuracy_fn= accuracy_fn,\n",
    "        device = device\n",
    "    )\n",
    "\n",
    "\n",
    "# Calculate training time\n",
    "train_time_end_on_gpu = timer()\n",
    "total_train_time_model_0 = print_train_time(start=train_time_start_on_gpu,\n",
    "                                           end=train_time_end_on_gpu,\n",
    "                                           device=str(next(model_0.parameters()).device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predicitions and get model results\n",
    "\n",
    "def eval_model(model: torch.nn.Module,\n",
    "               dataloader: DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               accuracy_fn\n",
    "):\n",
    "    \"\"\"Returns a dictonary condataining prediciton parameter of a module\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): model to evaluate\n",
    "        dataloader (DataLoader): a dataloader that loads data by batches\n",
    "        loss_fn (torch.nn.Module): function that calculates loss\n",
    "        accuracy_fn (_type_): function that claculates accuracy\n",
    "    \"\"\"\n",
    "    loss, acc = 0,0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X,y in tqdm(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # Make predicitons\n",
    "            y_pred = model(X)\n",
    "\n",
    "            # Accumulate the loss and accuracy values\n",
    "            acc += accuracy_fn(y_true= y, y_pred= y_pred.argmax(dim=1))\n",
    "            loss = loss_fn(y_pred, y)\n",
    "\n",
    "        #Scale loss and acc to find the average loss/acc per batch\n",
    "        loss /= len(dataloader)\n",
    "        acc /= len(dataloader)\n",
    "\n",
    "    return {\n",
    "        \"model_name\" : model.__class__.__name__,\n",
    "        \"model_loss\": loss.item(),\n",
    "        \"model_acc\": acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function to calculate\n",
    "model0_results = eval_model(\n",
    "    model=model_0,\n",
    "    dataloader= test_dataloader,\n",
    "    accuracy_fn= accuracy_fn,\n",
    "    loss_fn= loss_fn\n",
    ")\n",
    "print(model0_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creatiung a convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTModelv2(nn.Module):\n",
    "    \"\"\"\n",
    "    Model architechture that replicates the TinyVGG\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 input_shape: int,\n",
    "                 hidden_units: int,\n",
    "                 output_shape: int):\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels= input_shape,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size= 3,\n",
    "                stride = 1,\n",
    "                padding=1), #Setting hyperparameters for 2d data\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels= hidden_units,\n",
    "                out_channels= hidden_units,\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "                stride=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "                stride=1\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "                stride=1\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d( kernel_size=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(\n",
    "                in_features= hidden_units*7*7,\n",
    "                out_features= output_shape\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model_2 = FashionMNISTModelv2(\n",
    "    input_shape= 1,\n",
    "    hidden_units= 10,\n",
    "    output_shape= len(class_names)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup a loss and optimizer funciton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(\n",
    "    params=model_2.parameters(),\n",
    "    lr=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "from helper_functions import accuracy_fn\n",
    "\n",
    "# Set the seed and start the timer\n",
    "torch.manual_seed(42)\n",
    "train_time_start_on_gpu = timer()\n",
    "\n",
    "\n",
    "# Set the number of epochs (we'll keep this small for faster training times)\n",
    "epochs = 3\n",
    "\n",
    "# Create training and testing loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n-------\")\n",
    "\n",
    "    #Train\n",
    "    train_step(\n",
    "        model= model_2,\n",
    "        data_loader= train_dataloader,\n",
    "        loss_fn= loss_fn,\n",
    "        optimizer= optimizer,\n",
    "        accuracy_fn= accuracy_fn,\n",
    "        device= device\n",
    "    )\n",
    "\n",
    "    #test\n",
    "    test_step(\n",
    "        model= model_2,\n",
    "        data_loader= test_dataloader,\n",
    "        loss_fn= loss_fn,\n",
    "        accuracy_fn= accuracy_fn,\n",
    "        device = device\n",
    "    )\n",
    "\n",
    "\n",
    "# Calculate training time\n",
    "train_time_end_on_gpu = timer()\n",
    "total_train_time_model_0 = print_train_time(start=train_time_start_on_gpu,\n",
    "                                           end=train_time_end_on_gpu,\n",
    "                                           device=str(next(model_2.parameters()).device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
